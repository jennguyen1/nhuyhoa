---
layout: post
title: "OLS: Analysis of Variance"
date: "October 22, 2015"
categories: ['statistics', 'regression analysis']
---

* TOC
{:toc}

```{r, echo = FALSE}
library(jn.general)
```

# Analysis of Variance
We can use theory (see [here][stat_theory_link]{:target = "_blank"}) to conduct hypothesis tests regarding models. 

The basic idea here is to compare the variance accounted for by the covariates to the variance of the error. We can do that by computing the test statistic $$F = \frac{SS_R/df_R}{SS_E/df_E} $$, where $$SS_R$$ and $$df_R$$ are the sums of squares and degrees of freedom accounted for by the covariates and $$SS_E$$ and $$df_E$$ are the sums of squares and degrees of freedom of the error. Recall from above that this is the $$ F $$ distribution with $$ df_R, df_E $$ degrees of freedom. Use this distribution to determine if the ratio observed is too great to be due to chance.

Consider a simple case, where the responses are continuous and the covariates are categorical. 

```{r}
# fit model
m <- lm(Petal.Length ~ Species, data = iris)
# anova table
anova(m)
```

Here we see that the $$F$$ statistic, a ratio of the mean square errors, is too big to be due to chance with a p-value < 0.05. This means that the variability accounted for by the $$Species$$ variable is significantly greater than the variability of the error (unexplained variability). Another way to say this is that the variability between $$Species$$ is significantly greater than the pooled variability within treatments, assuming all treatments have equal variance. 

This basic case is known as single-factor ANOVA. The procedures here can be extended to any model, with categorical or continuous variables. 

Consider the follow model:
```{r}
# fit model
m <- lm(Sepal.Length ~ Petal.Length * Species, data = iris)
# anova table
anova(m)
```

We had looked at the summary table for this model in a previous post. The results of an analysis of variance table should be read in a certain order. 
  
* 1st row: variance accounted for by $$Petal.Length$$ is significantly greater than the unexplained variance
* 2nd row: after $$Petal.Length$$ has been taken into consideration, the variance accounted for by $$Species$$ is signficantly greater than the unexplained variance
* 3rd row: after $$Petal.Length$$ and $$Species$$ have been taken into consideration, the variance accounted for by the interaction of $$Petal.Length$$ and $$Species$$ is not significantly different than the variance of the error

These extensions from the basic case are known as ANCOVA (analysis of covariance), MANOVA (multivariate analysis of variance), and MANCOVA (multivariate analysis of variance). They can all be assessed with linear models using the summary table or anova table in R.

# Comparing Models
Suppose we want to compare 2 models, where one is nested in the other. Let $$R$$ correspond to the reduced model with $$p - q$$ parameters. Let $$F$$ correspond to the full model with $$p$$ parameters. Then we can compare the two models with a test statistic

$$ F = \frac{(SSE_R - SSE_F)/ (df_F - df_R)}{SSE_F/df_F} $$

where $$ F $$ ~ $$ F_{q, n - p} $$ and $$SSE$$ is the sum square errors and $$DF$$ is the residual degrees of freedom corresponding to the specified model.

Let's look at an example:
```{r}
# fit models
modh <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)
moda <- lm(Sepal.Length ~ Petal.Length * Species, data = iris)

# obtain the sum square error
RSSh <- anova(modh)["Sum Sq"][3,1]
RSSa <- anova(moda)["Sum Sq"][4,1]

# compute the F statistic & p-value by hand
F <- (RSSh - RSSa) / (2) / (RSSa/144)
pf(F, 2, 144, lower.tail = FALSE)

# using built in R
anova(modh, moda)
```

Thus we conclude that for this data set, the full and simplified model are not significantly different from each other. The interaction term is not significantly different from $$0$$, meaning that the slope of $$Petal.Length$$ on $$Sepal.Length$$ is the same for all species. 

[stat_theory_link]: http://jnguyen92.github.io/nhuyhoa//2015/10/OLS-and-ANOVA.html#distributions-of-common-statistics